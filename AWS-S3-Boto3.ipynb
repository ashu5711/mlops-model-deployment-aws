{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## List S3 Buckets and Create an S3 Bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "\n",
    "s3 = boto3.client('s3')\n",
    "\n",
    "bucket_name = 'somerandomashustorage'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'RequestId': 'J88Y4PC655VGQTST',\n",
       "  'HostId': '2ojMbcQc2sfJNqLm+NqlPxiNOTw7LNhQ5sYOFe76HsuH9Fy3zDRk+GQbs2pS2SPehxothSpoKn8=',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amz-id-2': '2ojMbcQc2sfJNqLm+NqlPxiNOTw7LNhQ5sYOFe76HsuH9Fy3zDRk+GQbs2pS2SPehxothSpoKn8=',\n",
       "   'x-amz-request-id': 'J88Y4PC655VGQTST',\n",
       "   'date': 'Wed, 30 Oct 2024 20:20:28 GMT',\n",
       "   'content-type': 'application/xml',\n",
       "   'transfer-encoding': 'chunked',\n",
       "   'server': 'AmazonS3'},\n",
       "  'RetryAttempts': 0},\n",
       " 'Buckets': [],\n",
       " 'Owner': {'DisplayName': 'ashutosh.shankar.a',\n",
       "  'ID': 'aaab05ff2b0bbe65c1e12ce2025cc296b1472b041cea20392b9e120e82a3864b'}}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = s3.list_buckets()\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bucket is created\n"
     ]
    }
   ],
   "source": [
    "def create_bucket(bucket_name):\n",
    "    s3.create_bucket(Bucket=bucket_name)\n",
    "    print('Bucket is created')\n",
    "\n",
    "create_bucket(bucket_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload a Single File to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "def upload_file(file_path,object_name=None):\n",
    "    if object_name == None:\n",
    "        object_name = os.path.basename(file_path)\n",
    "    s3.upload_file(file_path, bucket_name, object_name)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "upload_file('data/index.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "upload_file('data/index.html', 'somefile.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## List all objects in a bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'RequestId': 'HP9A6VRQC7M30RSA',\n",
       "  'HostId': 'vh+fFjJSOiTWZ7Ggd5vqwc4kI5JpwcomCCWq7qp5OMjvdkCnvJfOeK2dh1b/2O9SRontr7ELoRQ=',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amz-id-2': 'vh+fFjJSOiTWZ7Ggd5vqwc4kI5JpwcomCCWq7qp5OMjvdkCnvJfOeK2dh1b/2O9SRontr7ELoRQ=',\n",
       "   'x-amz-request-id': 'HP9A6VRQC7M30RSA',\n",
       "   'date': 'Wed, 30 Oct 2024 20:39:55 GMT',\n",
       "   'x-amz-bucket-region': 'us-east-1',\n",
       "   'content-type': 'application/xml',\n",
       "   'transfer-encoding': 'chunked',\n",
       "   'server': 'AmazonS3'},\n",
       "  'RetryAttempts': 0},\n",
       " 'IsTruncated': False,\n",
       " 'Contents': [{'Key': 'index.html',\n",
       "   'LastModified': datetime.datetime(2024, 10, 30, 20, 37, 27, tzinfo=tzutc()),\n",
       "   'ETag': '\"be89714840f63aec115562d5f747fca9\"',\n",
       "   'Size': 43,\n",
       "   'StorageClass': 'STANDARD'},\n",
       "  {'Key': 'somefile.html',\n",
       "   'LastModified': datetime.datetime(2024, 10, 30, 20, 38, 20, tzinfo=tzutc()),\n",
       "   'ETag': '\"be89714840f63aec115562d5f747fca9\"',\n",
       "   'Size': 43,\n",
       "   'StorageClass': 'STANDARD'}],\n",
       " 'Name': 'somerandomashustorage',\n",
       " 'Prefix': '',\n",
       " 'MaxKeys': 1000,\n",
       " 'EncodingType': 'url',\n",
       " 'KeyCount': 2}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s3.list_objects_v2(Bucket=bucket_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index.html\n",
      "somefile.html\n"
     ]
    }
   ],
   "source": [
    "def list_objects():\n",
    "    response = s3.list_objects_v2(Bucket =bucket_name)\n",
    "    for _ in response['Contents']:\n",
    "        print(_['Key'])\n",
    "        \n",
    "list_objects()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download S3 File to Local System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_file(object_name, file_path):\n",
    "    if not os.path.exists(os.path.dirname(file_path)):\n",
    "        os.makedirs(os.path.dirname(file_path))\n",
    "    s3.download_file(bucket_name, object_name, file_path)\n",
    "    \n",
    "download_file('index.html', 'data_downlaods/index.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload folder to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data [] ['panda-1236875_640.jpg', 'index.html', 'water-5393919_1280.jpg']\n"
     ]
    }
   ],
   "source": [
    "for root, dirs, files in os.walk('data'):\n",
    "    print(root,dirs,files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upload_directory(directory_path, s3_prefix):\n",
    "    for root, dirs, files in os.walk('data'):\n",
    "        for file in files:\n",
    "            file_path = os.path.join(root, file)\n",
    "            relpath = os.path.relpath(file_path, directory_path)\n",
    "            # print(relpath)\n",
    "            s3_key = os.path.join(s3_prefix, relpath)\n",
    "            # print(s3_key)\n",
    "            \n",
    "            s3.upload_file(file_path,bucket_name,s3_key)\n",
    "\n",
    "upload_directory('data', 's3_data')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download S3 Folder to Local System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_path = 's3_download_1'\n",
    "s3_prefix = 's3_data'\n",
    "\n",
    "def download_dir(local_path, s3_prefix):\n",
    "    os.makedirs(local_path, exist_ok=True)\n",
    "    paginator = s3.get_paginator('list_objects_v2')\n",
    "    for result in paginator.paginate(Bucket=bucket_name, Prefix=s3_prefix):\n",
    "        if 'Contents' in result:\n",
    "            for key in result['Contents']:\n",
    "                s3_key = key['Key']\n",
    "\n",
    "                local_file = os.path.join(local_path, os.path.relpath(s3_key, s3_prefix))\n",
    "                # os.makedirs(os.path.dirname(local_file), exist_ok=True)\n",
    "\n",
    "                s3.download_file(bucket_name, s3_key, local_file)\n",
    "\n",
    "\n",
    "\n",
    "download_dir(local_path, s3_prefix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Delete All Files in an S3 Bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_objects():\n",
    "    response = s3.list_objects_v2(Bucket=bucket_name)\n",
    "\n",
    "    if 'Contents' in response:\n",
    "\n",
    "        for obj in response['Contents']:\n",
    "            s3.delete_object(Bucket=bucket_name, Key=obj['Key'])\n",
    "\n",
    "\n",
    "\n",
    "delete_objects()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'RequestId': '3WZEDMP944C0E2N6',\n",
       "  'HostId': 'Izz9UklE9nYxJHNnbWE6g4LxDD8UueI0MSxaEzcsQNF6hGkfRH8Vt9H1WkW9Rse2P3hCSTnX6ezY1xTbUYEmFyRrrxR/uz2e29OSSYXkP6Q=',\n",
       "  'HTTPStatusCode': 204,\n",
       "  'HTTPHeaders': {'x-amz-id-2': 'Izz9UklE9nYxJHNnbWE6g4LxDD8UueI0MSxaEzcsQNF6hGkfRH8Vt9H1WkW9Rse2P3hCSTnX6ezY1xTbUYEmFyRrrxR/uz2e29OSSYXkP6Q=',\n",
       "   'x-amz-request-id': '3WZEDMP944C0E2N6',\n",
       "   'date': 'Wed, 30 Oct 2024 21:27:52 GMT',\n",
       "   'server': 'AmazonS3'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s3.delete_bucket(Bucket=bucket_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
